●
ILSVRC(The ImageNetLarge Scale Visual Recognition Challenge)
: 영상인식 관련 큰 대회 (그냥 ImageNet 대회 라고 함)

문제의 유형에 따라 적절한 아키텍쳐를 사용하자.

스냅샷성 데이터 -> 이미지ㅡ영상ㅡ바둑(?) -> CNN
    (snapshot)  (Convolutional Neural Network)
시퀀스성 데이터 -> 음성ㅡ언어ㅡ주식가격ㅡ맥락 -> RNN or LSTM
    (sequence)  (Recurrent Neural Network) (Long Short Term Memory)

VGG도 유명한 CNN구조중 하나이다.
    AlexNet - 구형
    VGG - 인기많고 많이 씀, 그냥 믿고 쓰는 느낌. ex) 라면스프같은 느낌
    GoogleNet - 처음엔 인기 없고, 뒤에 Inception 버전업 되고 좀 쓴다고 함.
    ResNet - 레이어가 매우 많다. 2017 10월기준 많이 쓰임
VGG는 구조가 직관적이고 성능도 상당히 쓸만해서 대중적으로 많이쓰인다.
(+ 다른 많은 구조의 재료가 되곤 함)

● VGGNet구조
조각을 보고, 패턴을 익히고, 점점 멀리서 조합을 본다.
    ex)
    1. 이미지를 눈 앞 1cm거리에서 본다고 생각하자
    -> 점과 선, 이상한 질감 몇개 밖에 모르겠다.
    2. 점과 선, 질감을 충분히 배우고, 조금 떨어져서 보자.
    -> 점과 선, 질감이 합쳐져 삼각형, 동그라미, 북실함 등이 보인다.
    3. 삼각형ㅡ원ㅡ사각형ㅡ북실함 등을 조합해서 보니
    -> 뾰족귀와 동그란 눈과 두툼한 발에 대해 배웠다.
    4. 더 멀리서 보니, 그것들이 모아져 있었고 이것은?
    -> 고양이 였다.

이러한 방식을 흉내내면 컴퓨터도 그림을 잘 볼 수 있지 않을까?

Q: 이미지에서는 인근 픽셀끼리만 상관있지 않나?
A: 가까운 것들끼리만 묶어서 계산하면 의미도 있고, 계산량도 줄어들것이다.
    (한픽셀과 모든 픽셀을 비교해보는 것보다 의미있고, 계산량도 줄어든다는 의미)
    Conovlution : 특정 패턴이 있는지 박스로 훑으며 마킹
        ex)
        위아래선필터, 좌우선필터, 대각선, A질감, B질감, 동그라미 등등
        여러가지 "조각"필터로 해당 패턴이 그림위에 있는지 확인한다.

        Convolution박스로 밀고나면, 숫자가 나온다. 
            (밀고간다 = 조각필터를 이미지의 부분부분마다 convolution연산 한다는 의미)
        그 숫자를 activation(주로 ReLU)에 넣어 나온 값 이걸로 이미지 지도를 새로 그린다.

        Conv연산을 할때 끝부분쪽이 짤리다보니, 사이즈 유지를 위해 conv연산 전에 0을 모서리에 추가하고 계산한다.
    
        - Convolution의 멋진점
            : 간단한 필터들이 쌓여가면서 엄청나게 복잡한 필터를 만들어 나가는 것
            이런 필터를 뉴럴넷이 알아서 찾아준다.
            즉, 부품을 조립해 더 복잡한 부품을 만든다.
    
Q: 이미지를 아까 1cm로 보고 그 후 점점 더 멀리서 본다고 했다. 이와같이 점점 더 멀리서 보는 법은 없을까?
A: 우리가 멀어져도 되지만 "그림을 줄여"도 된다.
    (사이즈를 점진적으로 줄이는 방법을 사용하자.)
    MaxPooling : n x n크기(pool)을 중요한 정보(Max)한개로 줄인다.
        선명한 정보만 남겨서, 판단과 학습이 쉬워지고 노이즈가 줄면서, 덤으로 융통성도 확보된다.
    
1. 패턴들을 쌓아가며 점차 복잡한 패던을 인식한다.(conv)
2. 사이즈를 줄여가며, 더욱 추상화 해나간다.(maxpooling)
-> 결국 후반에는 추상화 부품으로 남는다.

시작은 256 x 256픽셀을 다 보았어야 했지만 Conv와 Max Pooling의 반복으로 아래와 같은 이미지를 갖게 된다.
    ex)
    256x256의 이미지 
    
    ->

    0   1   1   1   0
    0   눈  눈  1   0
    0   코  입  귀  0
    0   0   목  0   0
    0   티  티  티  0

마지막에, 추상화가 끝난 데이터를 FC에 넣어 판단한다.
최종판단은 Fully Connected Layer로 계산하게 한다.
    ex)
    눈과 코와 귀가있고 티를 입고있으니 
    개      X
    고양이  X
    사람    O
    말      X

●●●●
뉴럴넷에게 답을 회신받는 3가지 방법 (Output의 종류?)
    1. Value
    :이게 얼마가 될 것 같아?
    -> output을 그냥 받는다.

    2. O / X
    : 맞냐? 아니냐?
    -> output에 sigmoid를 준다.

    3. Category
    : 이게 주어진 것들 중에 뭐냐?
    -> output에 softmax를 준다.

    그래서 1000개 종류 분류하는 아키텍쳐는 끝이 SoftMax로 되어있다.

    

